{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yaml\n",
    "import pandas as pd\n",
    "from pyprojroot import here\n",
    "from collections import Counter\n",
    "import os\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the Excel file and heck for Nan values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Index([], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "with open(here(\"configs/config.yml\")) as cfg:\n",
    "    cfg = yaml.load(cfg, Loader=yaml.FullLoader)\n",
    "questions_df = pd.read_excel(os.path.join(\n",
    "    here(cfg[\"eval_questions_dir\"]), cfg[\"eval_file_name\"]))\n",
    "final_df = pd.DataFrame(columns=[\"best_scorer\", \"num_top_appearance\"])\n",
    "\n",
    "print(questions_df[\"langchain_token_mmr_score\"].isna().sum())\n",
    "print(questions_df[questions_df[\"langchain_token_mmr_score\"].isna()].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['source', 'question', 'correct_answer', 'langchain_token_mmr_result',\n",
       "       'langchain_token_mmr_inference_time',\n",
       "       'langchain_recursive_similarity_result',\n",
       "       'langchain_recursive_similarity_inference_time',\n",
       "       'langchain_recursive_mmr_result',\n",
       "       'langchain_recursive_mmr_inference_time',\n",
       "       'llama_index_sentence_retrieval_result',\n",
       "       'llama_index_sentence_retrieval_inference_time',\n",
       "       'llama_index_auto_merging_retrieval_result',\n",
       "       'llama_index_auto_merging_retrieval_inference_time',\n",
       "       'langchain_recursive_similarity_score', 'langchain_recursive_mmr_score',\n",
       "       'llama_index_sentence_retrieval_score',\n",
       "       'llama_index_auto_merging_retrieval_score', 'lowest_score',\n",
       "       'highest_score', 'langchain_token_mmr_score',\n",
       "       'langchain_token_mmr_result_score', 'langchain_token_mmr_score_score',\n",
       "       '1) langchain_token_mmr_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute and print total scores (scores are from 40):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total scores:\n",
      "    langchain - token_mmr_total_score: 36.1, \n",
      "    langchain - recursive_similarity_total_score: 38.4,\n",
      "    langchain - recursive_mmr_total_score: 35.95,\n",
      "    llama_index - sentence_retrieval_score: 36.6,\n",
      "    llama_index - auto_merging_retrieval_total_score: 32.3\n"
     ]
    }
   ],
   "source": [
    "langchain_token_mmr_total_score = sum(questions_df[\"langchain_token_mmr_score\"])\n",
    "langchain_similarity_total_score = sum(questions_df[\"langchain_recursive_similarity_score\"])\n",
    "langchain_recursive_mmr_total_score = sum(questions_df[\"langchain_recursive_mmr_score\"])\n",
    "llama_index_sentence_retrieval_score = sum(questions_df[\"llama_index_sentence_retrieval_score\"])\n",
    "llama_index_auto_merging_retrieval_total_score = sum(questions_df[\"llama_index_auto_merging_retrieval_score\"])\n",
    "print(f\"Total scores:\\n\\\n",
    "    langchain - token_mmr_total_score: {round(langchain_token_mmr_total_score, 2)}, \\n\\\n",
    "    langchain - recursive_similarity_total_score: {round(langchain_similarity_total_score, 2)},\\n\\\n",
    "    langchain - recursive_mmr_total_score: {round(langchain_recursive_mmr_total_score, 2)},\\n\\\n",
    "    llama_index - sentence_retrieval_score: {round(llama_index_sentence_retrieval_score, 2)},\\n\\\n",
    "    llama_index - auto_merging_retrieval_total_score: {round(llama_index_auto_merging_retrieval_total_score, 2)}\")\n",
    "scorer_list = [langchain_token_mmr_total_score, langchain_similarity_total_score, langchain_recursive_mmr_total_score, llama_index_sentence_retrieval_score, llama_index_auto_merging_retrieval_total_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[\"best_scorer\"] = scorer_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df = questions_df[[\n",
    "    'langchain_token_mmr_score',\n",
    "    'langchain_recursive_similarity_score',\n",
    "    'langchain_recursive_mmr_score',\n",
    "    'llama_index_sentence_retrieval_score',\n",
    "    'llama_index_auto_merging_retrieval_score']]\n",
    "max_cols = score_df.apply(lambda x: x[x == x.max()].index.tolist(), axis=1)\n",
    "max_cols_list = max_cols.to_list()\n",
    "max_cols_count = Counter([col for row in max_cols_list for col in row])\n",
    "\n",
    "min_cols = score_df.apply(lambda x: x[x == x.min()].index.tolist(), axis=1)\n",
    "min_cols_list = min_cols.to_list()\n",
    "min_cols_count = Counter([col for row in min_cols_list for col in row])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Count the number of times that each technique was among the highest scorers:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'langchain_recursive_similarity_score': 36,\n",
       "         'llama_index_sentence_retrieval_score': 34,\n",
       "         'langchain_recursive_mmr_score': 33,\n",
       "         'langchain_token_mmr_score': 33,\n",
       "         'llama_index_auto_merging_retrieval_score': 23})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_cols_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Count the number of times that each technique was among the lowest scorers:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'llama_index_auto_merging_retrieval_score': 32,\n",
       "         'langchain_token_mmr_score': 21,\n",
       "         'llama_index_sentence_retrieval_score': 21,\n",
       "         'langchain_recursive_mmr_score': 20,\n",
       "         'langchain_recursive_similarity_score': 19})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_cols_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.index = ['langchain_token_mmr', 'langchain_recursive_similarity', 'langchain_recursive_mmr', 'llama_index_sentence_retrieval', 'llama_index_auto_merging_retrieval']\n",
    "for idx, row in final_df.iterrows():\n",
    "    final_df.at[idx, \"num_top_appearance\"] = int(max_cols_count[f\"{idx}_score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Count the number of times that the method took zero score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total zero scores:\n",
      "    langchain_token_mmr: 2,\n",
      "    langchain_recursive_similarity: 1,\n",
      "    langchain_recursive_mmr: 2,\n",
      "    llama_index_sentence_retrieval: 1,\n",
      "    llama_index_auto_merging_retrieval: 3\n"
     ]
    }
   ],
   "source": [
    "def count_number_of_zero_scores(df, column_name):\n",
    "    return len(df[df[column_name]==0])\n",
    "\n",
    "langchain_token_mmr_total_zero_score = count_number_of_zero_scores(questions_df, \"langchain_token_mmr_score\")\n",
    "langchain_recursive_similarity_total_zero_score = count_number_of_zero_scores(questions_df, \"langchain_recursive_similarity_score\")\n",
    "langchain_recursive_mmr_total_zero_score = count_number_of_zero_scores(questions_df, \"langchain_recursive_mmr_score\")\n",
    "llama_index_sentence_retrieval_zero_score = count_number_of_zero_scores(questions_df, \"llama_index_sentence_retrieval_score\")\n",
    "llama_index_auto_merging_retrieval_total_zero_score = count_number_of_zero_scores(questions_df, \"llama_index_auto_merging_retrieval_score\")\n",
    "print(f\"Total zero scores:\\n\\\n",
    "    langchain_token_mmr: {langchain_token_mmr_total_zero_score},\\n\\\n",
    "    langchain_recursive_similarity: {langchain_recursive_similarity_total_zero_score},\\n\\\n",
    "    langchain_recursive_mmr: {langchain_recursive_mmr_total_zero_score},\\n\\\n",
    "    llama_index_sentence_retrieval: {llama_index_sentence_retrieval_zero_score},\\n\\\n",
    "    llama_index_auto_merging_retrieval: {llama_index_auto_merging_retrieval_total_zero_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis based on each document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Score of each technique on each document**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>langchain_token_mmr_score</th>\n",
       "      <th>langchain_recursive_similarity_score</th>\n",
       "      <th>langchain_recursive_mmr_score</th>\n",
       "      <th>llama_index_sentence_retrieval_score</th>\n",
       "      <th>llama_index_auto_merging_retrieval_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SegmentAnything paper</th>\n",
       "      <td>13.3</td>\n",
       "      <td>13.6</td>\n",
       "      <td>12.20</td>\n",
       "      <td>12.8</td>\n",
       "      <td>10.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product scpecification</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stories</th>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.75</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>technical support</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.3</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vision transformer paper</th>\n",
       "      <td>10.3</td>\n",
       "      <td>10.8</td>\n",
       "      <td>11.00</td>\n",
       "      <td>10.5</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          langchain_token_mmr_score  \\\n",
       "source                                                \n",
       "SegmentAnything paper                          13.3   \n",
       "product scpecification                          3.0   \n",
       "stories                                         4.5   \n",
       "technical support                               5.0   \n",
       "vision transformer paper                       10.3   \n",
       "\n",
       "                          langchain_recursive_similarity_score  \\\n",
       "source                                                           \n",
       "SegmentAnything paper                                     13.6   \n",
       "product scpecification                                     4.0   \n",
       "stories                                                    5.0   \n",
       "technical support                                          5.0   \n",
       "vision transformer paper                                  10.8   \n",
       "\n",
       "                          langchain_recursive_mmr_score  \\\n",
       "source                                                    \n",
       "SegmentAnything paper                             12.20   \n",
       "product scpecification                             3.00   \n",
       "stories                                            4.75   \n",
       "technical support                                  5.00   \n",
       "vision transformer paper                          11.00   \n",
       "\n",
       "                          llama_index_sentence_retrieval_score  \\\n",
       "source                                                           \n",
       "SegmentAnything paper                                     12.8   \n",
       "product scpecification                                     4.5   \n",
       "stories                                                    4.5   \n",
       "technical support                                          4.3   \n",
       "vision transformer paper                                  10.5   \n",
       "\n",
       "                          llama_index_auto_merging_retrieval_score  \n",
       "source                                                              \n",
       "SegmentAnything paper                                         10.8  \n",
       "product scpecification                                         4.0  \n",
       "stories                                                        3.3  \n",
       "technical support                                              5.0  \n",
       "vision transformer paper                                       9.2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "langchain_token_mmr_df = questions_df.pivot_table(index='source', columns=None, values='langchain_token_mmr_score', aggfunc='sum')\n",
    "langchain_recursive_similarity_df = questions_df.pivot_table(index='source', columns=None, values='langchain_recursive_similarity_score', aggfunc='sum')\n",
    "langchain_recursive_mmr_df = questions_df.pivot_table(index='source', columns=None, values='langchain_recursive_mmr_score', aggfunc='sum')\n",
    "llama_index_sentence_df = questions_df.pivot_table(index='source', columns=None, values='llama_index_sentence_retrieval_score', aggfunc='sum')\n",
    "llama_index_auto_merging_df = questions_df.pivot_table(index='source', columns=None, values='llama_index_auto_merging_retrieval_score', aggfunc='sum')\n",
    "\n",
    "# Concatenate the DataFrames into a single DataFrame\n",
    "result_df = pd.concat([langchain_token_mmr_df, langchain_recursive_similarity_df, langchain_recursive_mmr_df, llama_index_sentence_df, llama_index_auto_merging_df], axis=1)\n",
    "\n",
    "# Rename the columns to match your desired output\n",
    "result_df.columns = [\n",
    "    'langchain_token_mmr_score',\n",
    "    'langchain_recursive_similarity_score',\n",
    "    'langchain_recursive_mmr_score',\n",
    "    'llama_index_sentence_retrieval_score',\n",
    "    'llama_index_auto_merging_retrieval_score'\n",
    "    ]\n",
    "\n",
    "# Display the result\n",
    "display(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Average score per document (normalized)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized average score per document:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'SegmentAnything paper': 0.9,\n",
       " 'product scpecification': 0.74,\n",
       " 'stories': 0.88,\n",
       " 'technical support': 0.97,\n",
       " 'vision transformer paper': 0.94}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Normalized average score per document:\")\n",
    "documents = [\"SegmentAnything paper\", \"product scpecification\", \"stories\", \"technical support\", \"vision transformer paper\"]\n",
    "num_questions = questions_df[[\"source\", \"question\"]].groupby(\"source\").count().values.tolist()\n",
    "num_questions = [val for sublist in num_questions for val in sublist]\n",
    "mean_doc_score = result_df.mean(axis=1).values.tolist()\n",
    "result = [round(x / y, 2) for x, y in zip(mean_doc_score, num_questions)]\n",
    "result_dict = {}\n",
    "for i in range(len(result)):\n",
    "    result_dict[documents[i]] = result[i]\n",
    "result_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference time analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Total inference time to answer 40 question**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_token_mmr_inference_time                    68.97\n",
       "langchain_recursive_mmr_inference_time                62.03\n",
       "langchain_recursive_similarity_inference_time         66.92\n",
       "llama_index_sentence_retrieval_inference_time        100.95\n",
       "llama_index_auto_merging_retrieval_inference_time     52.66\n",
       "dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_df[[\n",
    "    \"langchain_token_mmr_inference_time\",\n",
    "    \"langchain_recursive_mmr_inference_time\",\n",
    "    \"langchain_recursive_similarity_inference_time\",\n",
    "    \"llama_index_sentence_retrieval_inference_time\",\n",
    "    \"llama_index_auto_merging_retrieval_inference_time\"\n",
    "    ]].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Average inference time (AVG time per question)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_token_mmr_inference_time                   1.72425\n",
       "langchain_recursive_mmr_inference_time               1.55075\n",
       "langchain_recursive_similarity_inference_time        1.67300\n",
       "llama_index_sentence_retrieval_inference_time        2.52375\n",
       "llama_index_auto_merging_retrieval_inference_time    1.31650\n",
       "dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_df[[\n",
    "    \"langchain_token_mmr_inference_time\",\n",
    "    \"langchain_recursive_mmr_inference_time\",\n",
    "    \"langchain_recursive_similarity_inference_time\",\n",
    "    \"llama_index_sentence_retrieval_inference_time\",\n",
    "    \"llama_index_auto_merging_retrieval_inference_time\"\n",
    "    ]].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Fastest: llama_index - auto_merging_retrieval\n",
    "* slowest: llama_index - sentence_retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check the zero scored questions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama_index: auto_merging_retrieval\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>question</th>\n",
       "      <th>correct_answer</th>\n",
       "      <th>llama_index_auto_merging_retrieval_result</th>\n",
       "      <th>llama_index_auto_merging_retrieval_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stories</td>\n",
       "      <td>Who are Amarok, Fred, and Lily?</td>\n",
       "      <td>Amarok the Lone Wolf:\\n\\nAmarok is a lone wolf...</td>\n",
       "      <td>There is no information provided in the given ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>product scpecification</td>\n",
       "      <td>How much does CubeTriangle Kappa Portable Spea...</td>\n",
       "      <td>2000</td>\n",
       "      <td>The CubeTriangle Kappa Portable Speaker costs ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>SegmentAnything paper</td>\n",
       "      <td>How was the data engine used to collect the SA...</td>\n",
       "      <td>The data engine was used to collect the SA-1B ...</td>\n",
       "      <td>The data engine was used to collect the SA-1B ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    source                                           question  \\\n",
       "0                  stories                    Who are Amarok, Fred, and Lily?   \n",
       "13  product scpecification  How much does CubeTriangle Kappa Portable Spea...   \n",
       "30   SegmentAnything paper  How was the data engine used to collect the SA...   \n",
       "\n",
       "                                       correct_answer  \\\n",
       "0   Amarok the Lone Wolf:\\n\\nAmarok is a lone wolf...   \n",
       "13                                               2000   \n",
       "30  The data engine was used to collect the SA-1B ...   \n",
       "\n",
       "            llama_index_auto_merging_retrieval_result  \\\n",
       "0   There is no information provided in the given ...   \n",
       "13  The CubeTriangle Kappa Portable Speaker costs ...   \n",
       "30  The data engine was used to collect the SA-1B ...   \n",
       "\n",
       "    llama_index_auto_merging_retrieval_score  \n",
       "0                                        0.0  \n",
       "13                                       0.0  \n",
       "30                                       0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "Who are Amarok, Fred, and Lily?\n",
      "=====================\n",
      "Correct answer:\n",
      "Amarok the Lone Wolf:\n",
      "\n",
      "Amarok is a lone wolf living in the Alaskan mountains.\n",
      "Separated from his pack during a fierce winter storm, he embarks on a challenging journey to reunite with his family.\n",
      "The story highlights Amarok's resilience, the beauty of the Alaskan wilderness, and the emotional reunion with his pack.\n",
      "Fred the Red Fish:\n",
      "\n",
      "Fred is a small red fish living in a vibrant coral reef.\n",
      "His adventurous spirit leads him to discover a treasure map, prompting him to set off on a daring journey with his friend Delphi.\n",
      "The narrative explores the wonders and challenges of the ocean, emphasizing Fred's growth and realization that home is where love resides.\n",
      "Lily the Bee:\n",
      "\n",
      "Lily is a young bee living in Blossom Valley with a deep love for flowers and her family.\n",
      "Caught in a storm, Lily is carried far from home, leading her on an adventurous journey back.\n",
      "Throughout her odyssey, Lily encounters various creatures, overcomes obstacles, and ultimately returns wiser, stronger, and eager to share her experiences with her hive.\n",
      "\n",
      "Given answer:\n",
      "There is no information provided in the given context about Amarok, Fred, and Lily.\n",
      "------------------\n",
      "Question:\n",
      "How much does CubeTriangle Kappa Portable Speaker cost?\n",
      "=====================\n",
      "Correct answer:\n",
      "2000\n",
      "\n",
      "Given answer:\n",
      "The CubeTriangle Kappa Portable Speaker costs $800.\n",
      "------------------\n",
      "Question:\n",
      "How was the data engine used to collect the SA-1B mask dataset, and what were the three stages of the data collection process?\n",
      "=====================\n",
      "Correct answer:\n",
      "The data engine was used to collect the SA-1B mask dataset, which involved three stages of data collection. In the first stage, a team of professional annotators labeled masks by clicking foreground/background object points using a browser-based interactive segmentation tool powered by SAM. In the second stage, annotators were presented with images pre-filled with automatically detected confident masks and asked to annotate any additional unannotated objects. In the third stage, annotation was fully automatic using the ambiguity-aware model, which prompted the model with a regular grid of points and predicted a set of masks that may correspond to valid objects. The resulting dataset contained 1.1 billion high-quality masks.\n",
      "\n",
      "Given answer:\n",
      "The data engine was used to collect the SA-1B mask dataset fully automatically. The three stages of the data collection process were not explicitly mentioned in the given context.\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"llama_index: auto_merging_retrieval\")\n",
    "tmp_df = questions_df[[\"source\",\n",
    "                       \"question\",\n",
    "                       \"correct_answer\",\n",
    "                       \"llama_index_auto_merging_retrieval_result\",\n",
    "                       \"llama_index_auto_merging_retrieval_score\"\n",
    "                       ]][questions_df[\"llama_index_auto_merging_retrieval_score\"]==0]\n",
    "display(tmp_df)\n",
    "for idx, row in tmp_df.iterrows():\n",
    "    print(\"Question:\")\n",
    "    print(row[\"question\"])\n",
    "    print(\"=====================\")\n",
    "    print(\"Correct answer:\")\n",
    "    print(row[\"correct_answer\"])\n",
    "    print()\n",
    "    print(\"Given answer:\")\n",
    "    print(row[\"llama_index_auto_merging_retrieval_result\"])\n",
    "    print(\"------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama_index: sentence_retrieval\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>question</th>\n",
       "      <th>correct_answer</th>\n",
       "      <th>llama_index_sentence_retrieval_result</th>\n",
       "      <th>llama_index_sentence_retrieval_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>SegmentAnything paper</td>\n",
       "      <td>How was the data engine used to collect the SA...</td>\n",
       "      <td>The data engine was used to collect the SA-1B ...</td>\n",
       "      <td>The context does not provide information about...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   source                                           question  \\\n",
       "30  SegmentAnything paper  How was the data engine used to collect the SA...   \n",
       "\n",
       "                                       correct_answer  \\\n",
       "30  The data engine was used to collect the SA-1B ...   \n",
       "\n",
       "                llama_index_sentence_retrieval_result  \\\n",
       "30  The context does not provide information about...   \n",
       "\n",
       "    llama_index_sentence_retrieval_score  \n",
       "30                                   0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "How was the data engine used to collect the SA-1B mask dataset, and what were the three stages of the data collection process?\n",
      "==========================================\n",
      "Correct answer:\n",
      "The data engine was used to collect the SA-1B mask dataset, which involved three stages of data collection. In the first stage, a team of professional annotators labeled masks by clicking foreground/background object points using a browser-based interactive segmentation tool powered by SAM. In the second stage, annotators were presented with images pre-filled with automatically detected confident masks and asked to annotate any additional unannotated objects. In the third stage, annotation was fully automatic using the ambiguity-aware model, which prompted the model with a regular grid of points and predicted a set of masks that may correspond to valid objects. The resulting dataset contained 1.1 billion high-quality masks.\n",
      "\n",
      "Given answer:\n",
      "The context does not provide information about how the data engine was used to collect the SA-1B mask dataset or the three stages of the data collection process.\n",
      "------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"llama_index: sentence_retrieval\")\n",
    "tmp_df = questions_df[[\"source\",\n",
    "                       \"question\",\n",
    "                       \"correct_answer\",\n",
    "                       \"llama_index_sentence_retrieval_result\",\n",
    "                       \"llama_index_sentence_retrieval_score\"\n",
    "                       ]][questions_df[\"llama_index_sentence_retrieval_score\"]==0]\n",
    "display(tmp_df)\n",
    "for idx, row in tmp_df.iterrows():\n",
    "    print(\"Question:\")\n",
    "    print(row[\"question\"])\n",
    "    print(\"==========================================\")\n",
    "    print(\"Correct answer:\")\n",
    "    print(row[\"correct_answer\"])\n",
    "    print()\n",
    "    print(\"Given answer:\")\n",
    "    print(row[\"llama_index_sentence_retrieval_result\"])\n",
    "    print(\"------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "langchain: token_mmr\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>question</th>\n",
       "      <th>correct_answer</th>\n",
       "      <th>langchain_token_mmr_result</th>\n",
       "      <th>langchain_token_mmr_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>product scpecification</td>\n",
       "      <td>How much does CubeTriangle Kappa Portable Spea...</td>\n",
       "      <td>2000</td>\n",
       "      <td>The CubeTriangle Kappa Portable Speaker costs ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>product scpecification</td>\n",
       "      <td>Is there any skateboard with 20 mph top speed ...</td>\n",
       "      <td>Yes the CubeTriangle Chi Electric Skateboard h...</td>\n",
       "      <td>I'm sorry, but I couldn't find any information...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    source                                           question  \\\n",
       "13  product scpecification  How much does CubeTriangle Kappa Portable Spea...   \n",
       "14  product scpecification  Is there any skateboard with 20 mph top speed ...   \n",
       "\n",
       "                                       correct_answer  \\\n",
       "13                                               2000   \n",
       "14  Yes the CubeTriangle Chi Electric Skateboard h...   \n",
       "\n",
       "                           langchain_token_mmr_result  \\\n",
       "13  The CubeTriangle Kappa Portable Speaker costs ...   \n",
       "14  I'm sorry, but I couldn't find any information...   \n",
       "\n",
       "    langchain_token_mmr_score  \n",
       "13                        0.0  \n",
       "14                        0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "How much does CubeTriangle Kappa Portable Speaker cost?\n",
      "==========================================\n",
      "Correct answer:\n",
      "2000\n",
      "\n",
      "Given answer:\n",
      "The CubeTriangle Kappa Portable Speaker costs $1630.\n",
      "------------------------------------------------------\n",
      "Question:\n",
      "Is there any skateboard with 20 mph top speed with a 15-mile range on a single charge?\n",
      "==========================================\n",
      "Correct answer:\n",
      "Yes the CubeTriangle Chi Electric Skateboard has the specifications that you are looing for. Here are the features of this product:\n",
      "20 mph top speed with a 15-mile range on a single charge\n",
      "Regenerative braking and shock-absorbing wheels for a smooth ride\n",
      "Wireless remote control for effortless speed adjustments\n",
      "Durable, waterproof deck with integrated LED safety lights\n",
      "Companion app for route tracking and battery management\n",
      "Price: $780\n",
      "\n",
      "Given answer:\n",
      "I'm sorry, but I couldn't find any information about a skateboard with a 20 mph top speed and a 15-mile range on a single charge in the retrieved content.\n",
      "------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"langchain: token_mmr\")\n",
    "tmp_df = questions_df[[\"source\",\n",
    "                       \"question\",\n",
    "                       \"correct_answer\",\n",
    "                       \"langchain_token_mmr_result\",\n",
    "                       \"langchain_token_mmr_score\"\n",
    "                       ]][questions_df[\"langchain_token_mmr_score\"]==0]\n",
    "display(tmp_df)\n",
    "for idx, row in tmp_df.iterrows():\n",
    "    print(\"Question:\")\n",
    "    print(row[\"question\"])\n",
    "    print(\"==========================================\")\n",
    "    print(\"Correct answer:\")\n",
    "    print(row[\"correct_answer\"])\n",
    "    print()\n",
    "    print(\"Given answer:\")\n",
    "    print(row[\"langchain_token_mmr_result\"])\n",
    "    print(\"------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "langchain: recursive_mmr\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>question</th>\n",
       "      <th>correct_answer</th>\n",
       "      <th>langchain_recursive_mmr_result</th>\n",
       "      <th>langchain_recursive_mmr_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>product scpecification</td>\n",
       "      <td>How much does CubeTriangle Kappa Portable Spea...</td>\n",
       "      <td>2000</td>\n",
       "      <td>The CubeTriangle Kappa Portable Speaker is pri...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>product scpecification</td>\n",
       "      <td>Is there any skateboard with 20 mph top speed ...</td>\n",
       "      <td>Yes the CubeTriangle Chi Electric Skateboard h...</td>\n",
       "      <td>Based on the information from the vectorDB, th...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    source                                           question  \\\n",
       "13  product scpecification  How much does CubeTriangle Kappa Portable Spea...   \n",
       "14  product scpecification  Is there any skateboard with 20 mph top speed ...   \n",
       "\n",
       "                                       correct_answer  \\\n",
       "13                                               2000   \n",
       "14  Yes the CubeTriangle Chi Electric Skateboard h...   \n",
       "\n",
       "                       langchain_recursive_mmr_result  \\\n",
       "13  The CubeTriangle Kappa Portable Speaker is pri...   \n",
       "14  Based on the information from the vectorDB, th...   \n",
       "\n",
       "    langchain_recursive_mmr_score  \n",
       "13                            0.0  \n",
       "14                            0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "How much does CubeTriangle Kappa Portable Speaker cost?\n",
      "==========================================\n",
      "Correct answer:\n",
      "2000\n",
      "\n",
      "Given answer:\n",
      "The CubeTriangle Kappa Portable Speaker is priced at $730.\n",
      "------------------------------------------------------\n",
      "Question:\n",
      "Is there any skateboard with 20 mph top speed with a 15-mile range on a single charge?\n",
      "==========================================\n",
      "Correct answer:\n",
      "Yes the CubeTriangle Chi Electric Skateboard has the specifications that you are looing for. Here are the features of this product:\n",
      "20 mph top speed with a 15-mile range on a single charge\n",
      "Regenerative braking and shock-absorbing wheels for a smooth ride\n",
      "Wireless remote control for effortless speed adjustments\n",
      "Durable, waterproof deck with integrated LED safety lights\n",
      "Companion app for route tracking and battery management\n",
      "Price: $780\n",
      "\n",
      "Given answer:\n",
      "Based on the information from the vectorDB, there is no specific skateboard mentioned with a 20 mph top speed and a 15-mile range on a single charge. However, there is a CubeTriangle Theta -2 Electric Scooter Pro mentioned with a top speed of 25 mph and an extended 20-mile range. It is important to note that skateboards and electric scooters are different types of vehicles.\n",
      "------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"langchain: recursive_mmr\")\n",
    "tmp_df = questions_df[[\"source\",\n",
    "                       \"question\",\n",
    "                       \"correct_answer\",\n",
    "                       \"langchain_recursive_mmr_result\",\n",
    "                       \"langchain_recursive_mmr_score\"\n",
    "                       ]][questions_df[\"langchain_recursive_mmr_score\"]==0]\n",
    "display(tmp_df)\n",
    "for idx, row in tmp_df.iterrows():\n",
    "    print(\"Question:\")\n",
    "    print(row[\"question\"])\n",
    "    print(\"==========================================\")\n",
    "    print(\"Correct answer:\")\n",
    "    print(row[\"correct_answer\"])\n",
    "    print()\n",
    "    print(\"Given answer:\")\n",
    "    print(row[\"langchain_recursive_mmr_result\"])\n",
    "    print(\"------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "langchain: recursive_similarity\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>question</th>\n",
       "      <th>correct_answer</th>\n",
       "      <th>langchain_recursive_similarity_result</th>\n",
       "      <th>langchain_recursive_similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>product scpecification</td>\n",
       "      <td>How much does CubeTriangle Kappa Portable Spea...</td>\n",
       "      <td>2000</td>\n",
       "      <td>The CubeTriangle Kappa Portable Speaker is pri...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    source                                           question  \\\n",
       "13  product scpecification  How much does CubeTriangle Kappa Portable Spea...   \n",
       "\n",
       "   correct_answer              langchain_recursive_similarity_result  \\\n",
       "13           2000  The CubeTriangle Kappa Portable Speaker is pri...   \n",
       "\n",
       "    langchain_recursive_similarity_score  \n",
       "13                                   0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "How much does CubeTriangle Kappa Portable Speaker cost?\n",
      "==========================================\n",
      "Correct answer:\n",
      "2000\n",
      "\n",
      "Given answer:\n",
      "The CubeTriangle Kappa Portable Speaker is priced at $430.\n",
      "------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"langchain: recursive_similarity\")\n",
    "tmp_df = questions_df[[\"source\",\n",
    "                       \"question\",\n",
    "                       \"correct_answer\",\n",
    "                       \"langchain_recursive_similarity_result\",\n",
    "                       \"langchain_recursive_similarity_score\"\n",
    "                       ]][questions_df[\"langchain_recursive_similarity_score\"]==0]\n",
    "display(tmp_df)\n",
    "for idx, row in tmp_df.iterrows():\n",
    "    print(\"Question:\")\n",
    "    print(row[\"question\"])\n",
    "    print(\"==========================================\")\n",
    "    print(\"Correct answer:\")\n",
    "    print(row[\"correct_answer\"])\n",
    "    print()\n",
    "    print(\"Given answer:\")\n",
    "    print(row[\"langchain_recursive_similarity_result\"])\n",
    "    print(\"------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.reset_index().rename(columns={'index': 'method'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['num_top_appearance'] = final_df['num_top_appearance'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "<b>%{hovertext}</b><br><br>method=%{x}<br>best_scorer=%{y}<br>num_top_appearance=%{marker.size}<extra></extra>",
         "hovertext": [
          "langchain_token_mmr"
         ],
         "legendgroup": "langchain_token_mmr",
         "marker": {
          "color": "#636EFA",
          "line": {
           "color": "darkgrey",
           "width": 3
          },
          "size": [
           33
          ],
          "sizemode": "area",
          "sizeref": 0.09,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "langchain_token_mmr",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "langchain_token_mmr"
         ],
         "xaxis": "x",
         "y": [
          36.1
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "<b>%{hovertext}</b><br><br>method=%{x}<br>best_scorer=%{y}<br>num_top_appearance=%{marker.size}<extra></extra>",
         "hovertext": [
          "langchain_recursive_similarity"
         ],
         "legendgroup": "langchain_recursive_similarity",
         "marker": {
          "color": "#EF553B",
          "line": {
           "color": "darkgrey",
           "width": 3
          },
          "size": [
           36
          ],
          "sizemode": "area",
          "sizeref": 0.09,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "langchain_recursive_similarity",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "langchain_recursive_similarity"
         ],
         "xaxis": "x",
         "y": [
          38.4
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "<b>%{hovertext}</b><br><br>method=%{x}<br>best_scorer=%{y}<br>num_top_appearance=%{marker.size}<extra></extra>",
         "hovertext": [
          "langchain_recursive_mmr"
         ],
         "legendgroup": "langchain_recursive_mmr",
         "marker": {
          "color": "#00CC96",
          "line": {
           "color": "darkgrey",
           "width": 3
          },
          "size": [
           33
          ],
          "sizemode": "area",
          "sizeref": 0.09,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "langchain_recursive_mmr",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "langchain_recursive_mmr"
         ],
         "xaxis": "x",
         "y": [
          35.95
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "<b>%{hovertext}</b><br><br>method=%{x}<br>best_scorer=%{y}<br>num_top_appearance=%{marker.size}<extra></extra>",
         "hovertext": [
          "llama_index_sentence_retrieval"
         ],
         "legendgroup": "llama_index_sentence_retrieval",
         "marker": {
          "color": "#AB63FA",
          "line": {
           "color": "darkgrey",
           "width": 3
          },
          "size": [
           34
          ],
          "sizemode": "area",
          "sizeref": 0.09,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "llama_index_sentence_retrieval",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "llama_index_sentence_retrieval"
         ],
         "xaxis": "x",
         "y": [
          36.6
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "<b>%{hovertext}</b><br><br>method=%{x}<br>best_scorer=%{y}<br>num_top_appearance=%{marker.size}<extra></extra>",
         "hovertext": [
          "llama_index_auto_merging_retrieval"
         ],
         "legendgroup": "llama_index_auto_merging_retrieval",
         "marker": {
          "color": "#FFA15A",
          "line": {
           "color": "darkgrey",
           "width": 3
          },
          "size": [
           23
          ],
          "sizemode": "area",
          "sizeref": 0.09,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "llama_index_auto_merging_retrieval",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "llama_index_auto_merging_retrieval"
         ],
         "xaxis": "x",
         "y": [
          32.300000000000004
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "height": 600,
        "legend": {
         "bgcolor": "lightgrey",
         "bordercolor": "black",
         "borderwidth": 1,
         "font": {
          "color": "black",
          "family": "Arial, sans-serif",
          "size": 16
         },
         "itemsizing": "constant",
         "title": {
          "text": "Methods"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "b": 60,
         "l": 60,
         "r": 60,
         "t": 60
        },
        "paper_bgcolor": "white",
        "plot_bgcolor": "white",
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "color": "black",
          "family": "Arial, sans-serif",
          "size": 24
         },
         "text": "<b>Best RAG scorer<b>",
         "x": 0.5
        },
        "width": 1800,
        "xaxis": {
         "anchor": "y",
         "categoryarray": [
          "langchain_token_mmr",
          "langchain_recursive_similarity",
          "langchain_recursive_mmr",
          "llama_index_sentence_retrieval",
          "llama_index_auto_merging_retrieval"
         ],
         "categoryorder": "array",
         "domain": [
          0,
          1
         ],
         "showgrid": true,
         "tickangle": 45,
         "tickfont": {
          "color": "black",
          "family": "Arial, sans-serif",
          "size": 18
         },
         "title": {
          "font": {
           "size": 24
          },
          "text": "<b>Methods<b>"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "gridcolor": "lightgrey",
         "showgrid": true,
         "tickfont": {
          "color": "black",
          "family": "Arial, sans-serif",
          "size": 16
         },
         "title": {
          "font": {
           "color": "black",
           "family": "Arial, sans-serif",
           "size": 18
          },
          "text": "<b>Scores<b>"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "color_sequence = px.colors.qualitative.Plotly\n",
    "\n",
    "# Create the scatter plot\n",
    "fig = px.scatter(\n",
    "    final_df,\n",
    "    x='method',\n",
    "    y='best_scorer',\n",
    "    size='num_top_appearance',\n",
    "    hover_name='method',\n",
    "    color='method',  # Assign colors based on the 'system' column\n",
    "    color_discrete_sequence=color_sequence,  # Use the defined color sequence\n",
    "    title='<b>Best RAG scorer<b>'\n",
    ")\n",
    "\n",
    "# Customize the layout\n",
    "fig.update_layout(\n",
    "    title_font=dict(family='Arial, sans-serif', size=24, color='black'),\n",
    "    title_x=0.5,  # Center the title\n",
    "    paper_bgcolor='white',  # Background color for the outer area\n",
    "    plot_bgcolor='white',  # Background color for the plot area\n",
    "    xaxis=dict(\n",
    "        title='<b>Methods<b>',\n",
    "        title_font=dict(size=24),\n",
    "        tickangle=45,  # Rotate labels\n",
    "        tickfont=dict(family='Arial, sans-serif', size=18, color='black'),\n",
    "        showgrid=True  # Hide gridlines\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='<b>Scores<b>',\n",
    "        title_font=dict(family='Arial, sans-serif', size=18, color='black'),\n",
    "        tickfont=dict(family='Arial, sans-serif', size=16, color='black'),\n",
    "        showgrid=True,  # Show gridlines\n",
    "        gridcolor='lightgrey'  # Gridline color\n",
    "    ),\n",
    "    legend=dict(\n",
    "        title='Methods',\n",
    "        font=dict(family='Arial, sans-serif', size=16, color='black',),\n",
    "        bgcolor='lightgrey',  # Background color for the legend\n",
    "        bordercolor='black',  # Border color for the legend\n",
    "        borderwidth=1\n",
    "    ),\n",
    "    margin=dict(l=60, r=60, t=60, b=60),  # Adjust margins to fit labels\n",
    "    width=1800,  # Width of the entire plot image\n",
    "    height=600  # Height of the entire plot image\n",
    ")\n",
    "\n",
    "# Customize marker appearance\n",
    "fig.update_traces(\n",
    "    marker=dict(\n",
    "        line=dict(width=3, color='darkgrey')  # Border line for markers\n",
    "    ),\n",
    "    selector=dict(mode='markers')\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AR-RT-LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
