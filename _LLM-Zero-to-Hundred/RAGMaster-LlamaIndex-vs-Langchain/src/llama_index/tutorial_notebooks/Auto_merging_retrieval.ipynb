{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyprojroot import here\n",
    "from llama_index.llms import AzureOpenAI\n",
    "from llama_index.embeddings import AzureOpenAIEmbedding\n",
    "from llama_index.node_parser import get_leaf_nodes, HierarchicalNodeParser\n",
    "from llama_index import (load_index_from_storage,\n",
    "                         set_global_service_context,\n",
    "                         ServiceContext,\n",
    "                         StorageContext,\n",
    "                         SimpleDirectoryReader,\n",
    "                         VectorStoreIndex)\n",
    "from llama_index.indices.postprocessor import SentenceTransformerRerank\n",
    "from llama_index.query_engine import RetrieverQueryEngine\n",
    "from llama_index.retrievers import AutoMergingRetriever\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the GPT model and the embedding model from AzureOpenAI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureOpenAI(\n",
    "    model=\"gpt-35-turbo-16k\",\n",
    "    engine=\"gpt-35-turbo-16k\",\n",
    "    deployment_name=os.getenv(\"gpt_deployment_name\"),\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    azure_endpoint=os.getenv(\"OPENAI_API_BASE\"),\n",
    "    api_version=os.getenv(\"OPENAI_API_VERSION\"),\n",
    ")\n",
    "embed_model = AzureOpenAIEmbedding(\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    deployment_name=os.getenv(\"embed_deployment_name\"),\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    azure_endpoint=os.getenv(\"OPENAI_API_BASE\"),\n",
    "    api_version=os.getenv(\"OPENAI_API_VERSION\"),\n",
    ")\n",
    "# NOTE: Uncomment if you want to use an open source embedding model\n",
    "# embed_model = \"local:BAAI/bge-small-en-v1.5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set the serivce context**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_context = ServiceContext.from_defaults(\n",
    "    llm=llm,\n",
    "    embed_model=embed_model,\n",
    ")\n",
    "\n",
    "set_global_service_context(service_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the documents**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader(\n",
    "    input_files=[here(f\"data/docs/{d}\") for d in os.listdir(here(\"data/docs\"))]\n",
    ").load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Process documents and prepare the index:**\n",
    "\n",
    "Processing steps for `Auto-merging retrieval`:\n",
    "\n",
    "* We create the parent node and the child nodes. Chunk sizes in this code are [2048, 512, 128]\n",
    "\n",
    "Functions:\n",
    "- build_automerging_index\n",
    "- get_automerging_query_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arguments\n",
    "save_dir=here(\"data/indexes/merging_index\")\n",
    "rerank_model = \"BAAI/bge-reranker-base\"\n",
    "similarity_top_k=12,\n",
    "rerank_top_n=2,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_automerging_index(\n",
    "    documents,\n",
    "    llm,\n",
    "    embed_model=\"local:BAAI/bge-small-en-v1.5\",\n",
    "    save_dir=save_dir,\n",
    "    chunk_sizes=None,\n",
    "):\n",
    "    chunk_sizes = chunk_sizes or [2048, 512, 128]\n",
    "    node_parser = HierarchicalNodeParser.from_defaults(chunk_sizes=chunk_sizes)\n",
    "    nodes = node_parser.get_nodes_from_documents(documents)\n",
    "    leaf_nodes = get_leaf_nodes(nodes)\n",
    "    merging_context = ServiceContext.from_defaults(\n",
    "        llm=llm,\n",
    "        embed_model=embed_model,\n",
    "    )\n",
    "    storage_context = StorageContext.from_defaults()\n",
    "    storage_context.docstore.add_documents(nodes)\n",
    "\n",
    "    if not os.path.exists(save_dir):\n",
    "        automerging_index = VectorStoreIndex(\n",
    "            leaf_nodes, storage_context=storage_context, service_context=merging_context\n",
    "        )\n",
    "        automerging_index.storage_context.persist(persist_dir=save_dir)\n",
    "    else:\n",
    "        automerging_index = load_index_from_storage(\n",
    "            StorageContext.from_defaults(persist_dir=save_dir),\n",
    "            service_context=merging_context,\n",
    "        )\n",
    "    return automerging_index\n",
    "\n",
    "automerging_index = build_automerging_index(\n",
    "    documents,\n",
    "    llm,\n",
    "    embed_model=embed_model,\n",
    "    save_dir=save_dir # save the index automatically from here or manually as below\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You can save the index separately if you wish**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "automerging_index.storage_context.persist(save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load index index separately**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rebuild storage context\n",
    "storage_context = StorageContext.from_defaults(persist_dir=save_dir)\n",
    "\n",
    "# Load index from the storage context\n",
    "automerging_index = load_index_from_storage(storage_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build the query engine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_automerging_query_engine(\n",
    "    automerging_index,\n",
    "    similarity_top_k:int=12,\n",
    "    rerank_top_n:int=2,\n",
    "):\n",
    "    base_retriever = automerging_index.as_retriever(\n",
    "        similarity_top_k=similarity_top_k)\n",
    "    retriever = AutoMergingRetriever(\n",
    "        base_retriever, automerging_index.storage_context, verbose=True\n",
    "    )\n",
    "    rerank = SentenceTransformerRerank(\n",
    "        top_n=rerank_top_n, model=\"BAAI/bge-reranker-base\"\n",
    "    )\n",
    "    auto_merging_engine = RetrieverQueryEngine.from_args(\n",
    "        retriever, node_postprocessors=[rerank]\n",
    "    )\n",
    "    return auto_merging_engine\n",
    "\n",
    "automerging_query_engine = get_automerging_query_engine(\n",
    "    automerging_index,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test with a query**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The architecture of the vision transformer model combines the Transformer architecture with convolutional networks. In computer vision tasks, attention is either used alongside convolutional networks or replaces specific components of convolutional networks while maintaining their overall structure. The vision transformer model achieves impressive results compared to state-of-the-art convolutional networks, while requiring fewer computational resources to train.\n"
     ]
    }
   ],
   "source": [
    "response = automerging_query_engine.query(\n",
    "    \"Explain is the architecture of vision transformer model\"\n",
    ")\n",
    "print(str(response))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI-RT-LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
