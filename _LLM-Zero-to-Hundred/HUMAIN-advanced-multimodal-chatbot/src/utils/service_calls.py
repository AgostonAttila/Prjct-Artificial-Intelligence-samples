
import requests
from utils.webragquery.wrq_utils import Apputils
from utils.webragquery.llm_rag import LLM_RAG
import re
from utils.web_servers.load_web_service_config import LoadWebServicesConfig

WEB_SERVICE_CFG = LoadWebServicesConfig()


class ServiceCall:
    @staticmethod
    def ask_stable_diffusion(message: str) -> str:
        """
        Send a message to the Stable Diffusion service to generate an image based on the given prompt.

        Args:
            message (str): The prompt message.

        Returns:
            str: The directory path of the generated image.

        Raises:
            Exception: If an error occurs during the request process.
        """
        try:
            data = {'prompt': message}
            response = requests.post(
                f'http://127.0.0.1:{WEB_SERVICE_CFG.stable_diffusion_service_port}/generate_image', json=data)
            if response.status_code == 200:
                image_dir = response.json()['text']
                return image_dir
            else:
                print("Error:", response.json())
        except Exception as e:
            print("Error sending message:", e)

    @staticmethod
    def speech_to_text(input_audio_block):
        """
        Convert audio input into text using the speech-to-text service.

        Args:
            input_audio_block: The input audio block.

        Returns:
            str: The converted text.

        Raises:
            Exception: If an error occurs during the conversion process.
        """
        print("Input audio block:", input_audio_block)
        print("Type of input audio block:", type(input_audio_block))
        try:
            sr, y = input_audio_block
            print(sr, y)
            data = {'sr': sr, 'y': y.tolist()}
            response = requests.post(
                f'http://127.0.0.1:{WEB_SERVICE_CFG.whisper_service_port}/speech_to_text', json=data)
            if response.status_code == 200:
                message = response.json()['text']
                return message
            else:
                print("Error:", response.json())
        except Exception as e:
            print("Error sending audio:", e)

    @staticmethod
    def ask_rag_with_website_llm(wrq_config: object, message: str, chat_history: str, k: int, rag_search_type: str) -> str:
        """
        Generate a response using RAG (Retrieval Augmented Generation) with GPT model.

        Args:
            wrq_config (object): Configuration object containing system parameters.
            message (str): User query message.
            chat_history (str): Chat history to provide context for the response.

        Returns:
            str: The response generated by the RAG pipeline with the LLM.
        """
        latest_folder = Apputils.find_latest_chroma_folder(
            folder_path=wrq_config.persist_directory)
        print(latest_folder)
        llm_rag_instance = LLM_RAG(persist_directory=latest_folder, user_query=message, k=k, rag_search_type=rag_search_type, lambda_param=wrq_config.lambda_param, fetch_k=wrq_config.fetch_k,
                                   input_chat_history=chat_history, llm_system_role=wrq_config.llm_rag_system_role, gpt_model=wrq_config.llm_rag_gpt_model, temperature=wrq_config.llm_rag_temperature)
        llm_rag_full_response = llm_rag_instance.ask()
        return llm_rag_full_response["choices"][0]["message"]["content"]

    @staticmethod
    def ask_llava(message: str, llava_max_output_token: int, user_image_url: str):
        """
        Send a message to the LLAVA service for interaction, including a user image URL.

        Args:
            message (str): The prompt message.
            llava_max_output_token (int): The maximum number of tokens for LLAVA output.
            user_image_url (str): The URL of the user image.

        Returns:
            str: The generated text from LLAVA.

        Raises:
            Exception: If an error occurs during the interaction process.
        """
        try:
            data = {'prompt': message, "image_url": user_image_url,
                    "max_output_token": llava_max_output_token}
            response = requests.post(
                f'http://127.0.0.1:{WEB_SERVICE_CFG.llava_service_port}/interact_with_llava', json=data)
            if response.status_code == 200:
                text = response.json()['text']
                return text
            else:
                print("Error:", response.json())
        except Exception as e:
            print("Error sending message:", e)

    @staticmethod
    def remove_inst(text):
        """
        Remove the '[INST]' and '[/INST]' tags from the given text.

        Args:
            text (str): The input text containing '[INST]' and '[/INST]' tags.

        Returns:
            str: The text with the tags removed.

        """
        pattern = r'\[INST\].*?\[/INST\](.*)'
        match = re.match(pattern, text, re.DOTALL)
        if match:
            return match.group(1).strip()
        else:
            return text
